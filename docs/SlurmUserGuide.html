

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Slurm User Guide &mdash; UW-Madison Cryo-EM HPC 1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=f2a433a1"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="SlurmBatchScripts" href="SlurmBatchScripts.html" />
    <link rel="prev" title="About Slurm" href="AboutSlurm.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #C5050C" >

          
          
          <a href="index.html" class="icon icon-home">
            UW-Madison Cryo-EM HPC
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="GettingStarted/About.html">About</a></li>
<li class="toctree-l1"><a class="reference internal" href="GettingStarted/GettingStarted.html">Getting Started with the HPC Cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="GettingStarted/Forms.html">Forms</a></li>
<li class="toctree-l1"><a class="reference internal" href="Hardware.html">Hardware Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="Storage.html">Storage Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="Policies.html">Policies</a></li>
<li class="toctree-l1"><a class="reference internal" href="Support.html">Support</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Slurm Job Scheduler</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="AboutSlurm.html">About Slurm</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Slurm User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="SlurmBatchScripts.html">Slurm Batch Scripts</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Open OnDemand</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Access.html">Access and Logging In</a></li>
<li class="toctree-l1"><a class="reference internal" href="FileBrowser.html">File Browser</a></li>
<li class="toctree-l1"><a class="reference internal" href="Jobs.html">Jobs and Templates</a></li>
<li class="toctree-l1"><a class="reference internal" href="MonitoringJobs.html">Monitoring Jobs</a></li>
<li class="toctree-l1"><a class="reference internal" href="RemoteDesktop.html">Remote Desktop</a></li>
<li class="toctree-l1"><a class="reference internal" href="ShellAccess.html">Shell Access</a></li>
<li class="toctree-l1"><a class="reference internal" href="OtherApplications.html">Other Applications</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Supported Software</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Relion.html">RELION</a></li>
<li class="toctree-l1"><a class="reference internal" href="Imod.html">Imod</a></li>
<li class="toctree-l1"><a class="reference internal" href="Aretomo.html">Aretomo</a></li>
<li class="toctree-l1"><a class="reference internal" href="Chimera.html">Chimera(x)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Training and FAQs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Training.html">Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="Faqs.html">Frequently Asked Questions</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #C5050C" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">UW-Madison Cryo-EM HPC</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Slurm User Guide</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/SlurmUserGuide.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="slurm-user-guide">
<h1>Slurm User Guide<a class="headerlink" href="#slurm-user-guide" title="Link to this heading"></a></h1>
<p>Slurm is a cluster management and job scheduling system for Linux clusters. Slurm has three key functions. First, it allocates access to resources (compute nodes) to users so they can perform work. Second, it provides a framework for starting, executing, and monitoring work on the set of compute nodes. Finally, it manages a queue of pending work.</p>
<p>Users will access the main Slurm login node via SSH to run commands.</p>
<p>ssh -YC &lt;NetID&gt;&#64;wisc.edu&#64;cryoemcluster.biochem.wisc.edu</p>
<p>(Include -YC for X11 forwarding for any applications that require X11 windows such as RELION or IMOD).</p>
<p>Frequently used commands for end users:
sbatch: Submit a batch script for later execution</p>
<p>sbatch script.sh
srun: Submit a job to run immediately, run parallel tasks in an sbatch file, run an interactive gui job
srun -N4 -l /bin/hostname – will run hostname command on 4 nodes
srun -n4 -l /bin/hostname – will run hostname command on 4 processors</p>
<p>Easy job submission scripts:</p>
<p>Simple commands can be submitted with the helper scripts provided:</p>
<p><cite>submit_to_cpu.sh &lt;command arguments&gt;</cite> will submit a command into the CPU partition to run on a node, and can be used to quickly submit commands.</p>
<p><cite>submit_to_a5000.sh &lt;command arguments&gt;</cite> likewise will submit a command to the A5000 partition to run on NVIDIA A5000 GPU nodes.</p>
<p><cite>submit_to_a100.sh &lt;command arguments&gt;</cite> will submit to the A100 partition to run on the NVIDIA A100 GPU servers.
<cite>submit_to_gpu.sh &lt;command arguments&gt;</cite> will submit to any available GPU-containing server and request GPU resources.</p>
<p>By default, these GPU scripts request all available (4) GPUs per the server node for the submitted job.</p>
<p>Example here for submitting a command to run on a GPU server:</p>
<p>submit_to_a100.sh AreTomo -InMrc 1138_G1__L4_TS_001_aligned.st -OutMrc test_a100/tomogram.mrc -VolZ 1350 -AlignZ 1200 -OutBin 6 -DarkTol 0.1 -FlipVol 1 -Kv 300 -PixSize 1.4 -Wbp 1 -AngFile angles.txt -Patch 4 4 -TiltAxis 89.9
squeue: View information about jobs in scheduling queue.</p>
<blockquote>
<div><p>squeue – jobs 12345      view information about job 12345
squeue  –jobs 12345, 12346, 12347             view information about about jobs 12345, 12346, 12347</p>
</div></blockquote>
<p>[<a class="reference external" href="mailto:user&#37;&#52;&#48;biocsv-01627L">user<span>&#64;</span>biocsv-01627L</a> ~]$ squeue</p>
<blockquote>
<div><dl class="simple">
<dt>JOBID    PARTITION NAME  USER ST       TIME  NODES NODELIST(REASON)</dt><dd><p>53       cpu script.s user PD       0:00      1 (Resources)
54       cpu script.s user PD       0:00      1 (Priority)
55       cpu script.s user PD       0:00      1 (Priority)
49       cpu script.s user  R       0:38      1 biocsv-01669L
50       cpu script.s user  R       0:25      1 biocsv-01670L
51       cpu script.s user  R       0:22      1 biocsv-01671L
52       cpu script.s user  R       0:22      1 biocsv-01672L</p>
</dd>
</dl>
</div></blockquote>
<p>Job states (ST column):
* Most common states in bold
BF- Boot fail (usually hardware issue - contact Matt or Jennifer)
CA - Canceled
CD - Completed
CF - Configuring
CG - Completing
DL - Deadline (job terminated on deadline)
F - Failed
NF - Node Failed (contact Matt or Jennifer)
OOM - Out of memory
PD - Pending
PR - Job preempted
R - Job currently running
RD - Job being held due to reservation being deleted
RQ - Job being requeued
RH - Held job being requeued
RS - Job is about to change size
RV - Job revoked
SI - Job being signaled
SE - Job requeued in special state
SO - Job is staging out files
ST - Job has been stopped
S - Job has been suspended
TO - Job terminated upon reaching time limit
sinfo: Get information about compute nodes</p>
<p>[<a class="reference external" href="mailto:user&#37;&#52;&#48;biocsv-01627L">user<span>&#64;</span>biocsv-01627L</a> ~]$ sinfo
PARTITION AVAIL  TIMELIMIT  NODES  STATE NODELIST
a100         up   infinite      2   idle biocsv-01624L,biocsv-01625L
a5000        up   infinite      8   idle biocsv-01661L,biocsv-01662L,biocsv-01663L,biocsv-01664L,biocsv-01665L,biocsv-01666L,biocsv-01667L,biocsv-01668L
cpu*         up   infinite      4   idle biocsv-01669L,biocsv-01670L,biocsv-01671L,biocsv-01672L
sacct: Get information about pending, completed, and running jobs</p>
<p>[<a class="reference external" href="mailto:hpcadmin&#37;&#52;&#48;biocsv-01624L">hpcadmin<span>&#64;</span>biocsv-01624L</a> log]$ sacct –starttime 2023-11-1
JobID           JobName  Partition  Account    AllocCPUS   State     ExitCode
———— ———- ———- ———- ———- ———- ——–
234            hostname_+   a5000              2            FAILED     0:53
234.batch      batch                           2            CANCELLED  0:53
235            hostname     a5000              2            FAILED     0:53
scancel: Signal or cancel jobs, job arrays, or job steps.</p>
<blockquote>
<div><blockquote>
<div><p>scancel 55</p>
</div></blockquote>
<p>This will cancel job 55. Please don’t cancel other user’s jobs without speaking with them.</p>
</div></blockquote>
<p>Types of Nodes:</p>
<p>login node - node that schedules jobs for the compute nodes</p>
<blockquote>
<div><p>Used for data staging and submission of jobs into the SLURM cluster.
No local job running or CPU-intensive processes.</p>
</div></blockquote>
<p>a100 - uses Nvidia A100 GPUs - 2 of these compute nodes available</p>
<blockquote>
<div><p>2x AMD 7443 24-Core Processors (total of 96 threads)
4x A100 GPUs are available
512 GB total system memory available
Nodes are reserved for intensive machine learning jobs</p>
</div></blockquote>
<p>a5000 - users Nvidia A5000 GPUs - 8 of these compute nodes available</p>
<blockquote>
<div><p>1x AMD EPYC 7713P 64-Core Processor (total of 128 threads)
4x A5000 GPUs are available
512 GB total system memory available
Nodes are best used for conventional GPU processing jobs</p>
</div></blockquote>
<p>cpu - uses CPU only - no GPU - 4 of these compute nodes available</p>
<blockquote>
<div><p>1x AMD EPYC 7713P 64-Core Processor
No GPUs
256 GB total system memory available
Nodes are best used for interactive sessions, and non-GPU work</p>
</div></blockquote>
<p>Using GPUs in jobs:</p>
<p>example script:</p>
<blockquote>
<div><p>1 #!/bin/bash
2
3 #SBATCH –partition=a5000 –nodelist=biocsv-01662L   –gres=gpu:3. #use 3 gpus for job
4
5 srun –gres=gpu:1 hostname. #use 1 gpu for this command</p>
</div></blockquote>
<p>Control where job output goes:
use –chdir=*your directory* to do work in your directory (can be mounted file system ie. /mnt/remote/user
use –output=*your directory*/slurm-%j.out ie. /tmp/</p>
<dl class="simple">
<dt>example script:</dt><dd><p>1 #!/bin/bash
2
3 #SBATCH –partition=a5000 –nodelist=biocsv-01662L   –gres=gpu:3
4 #SBATCH –chdir=/mnt/remote
5 #SBATCH –output=/tmp/slurm-%j.out
6 srun –gres=gpu:1 hostname &gt;&gt; myfile.txt</p>
</dd>
</dl>
<p>More Slurm documentation available at: <a class="reference external" href="https://slurm.schedmd.com/">https://slurm.schedmd.com/</a></p>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="AboutSlurm.html" class="btn btn-neutral float-left" title="About Slurm" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="SlurmBatchScripts.html" class="btn btn-neutral float-right" title="SlurmBatchScripts" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Jennifer Scheuren.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>